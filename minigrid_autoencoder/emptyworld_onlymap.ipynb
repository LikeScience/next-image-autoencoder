{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9788dd5e",
   "metadata": {},
   "source": [
    "#### Imports and env creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b96a09a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.5.2 (SDL 2.28.2, Python 3.10.18)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "# from __future__ import annotations\n",
    "\n",
    "from minigrid.core.constants import COLOR_NAMES\n",
    "from minigrid.core.grid import Grid\n",
    "from minigrid.core.mission import MissionSpace\n",
    "from minigrid.core.world_object import Door, Goal, Key, Wall\n",
    "from minigrid.manual_control import ManualControl\n",
    "from minigrid.minigrid_env import MiniGridEnv\n",
    "from minigrid.core.constants import IDX_TO_OBJECT, OBJECT_TO_IDX\n",
    "\n",
    "from minigrid.core.actions import Actions\n",
    "from dataclasses import dataclass, field \n",
    "from typing import Set\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c267bc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  2  2  2  2]\n",
      " [ 2 10  1  1  2]\n",
      " [ 2  1  1  1  2]\n",
      " [ 2  1  1  8  2]\n",
      " [ 2  2  2  2  2]]\n"
     ]
    }
   ],
   "source": [
    "class SimpleEnv(MiniGridEnv):\n",
    "    def __init__(\n",
    "        self,\n",
    "        size=5,\n",
    "        agent_start_pos=(1, 1),\n",
    "        agent_start_dir=0,\n",
    "        max_steps: int | None = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        self.agent_start_pos = agent_start_pos\n",
    "        self.agent_start_dir = agent_start_dir\n",
    "\n",
    "        mission_space = MissionSpace(mission_func=self._gen_mission)\n",
    "\n",
    "        super().__init__(\n",
    "            mission_space=mission_space,\n",
    "            grid_size=size,\n",
    "            max_steps=256,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def _gen_mission():\n",
    "        return \"grand mission\"\n",
    "    # MiniGridEnv._gen_grid\n",
    "    \n",
    "    def _gen_grid(self, width, height):\n",
    "      self.grid = Grid(width, height)\n",
    "      self.grid.wall_rect(0, 0, width, height)\n",
    "\n",
    "      if self.agent_start_pos is not None:\n",
    "          self.agent_pos = self.agent_start_pos\n",
    "          self.agent_dir = self.agent_start_dir\n",
    "      else:\n",
    "          self.place_agent()\n",
    "      self.valid_actions = {Actions.left, Actions.right, Actions.forward}\n",
    "    \n",
    "      \n",
    "      self.put_obj(Goal(), width - 2, height - 2)\n",
    "\n",
    "    #   for i in range(0, height):\n",
    "    #     self.grid.set(5, i, Wall())\n",
    "\n",
    "    #   self.grid.set(5, 6, Door(COLOR_NAMES[0], is_locked=True))\n",
    "    #   self.grid.set(3, 6, Key(COLOR_NAMES[0]))\n",
    "    \n",
    "    def get_array_repr(self, with_agent=True):\n",
    "        grid_array = self.unwrapped.grid.encode()[:,:,0]\n",
    "        # print(grid_array)\n",
    "        # print(self.agent_pos)\n",
    "        grid_array[self.agent_pos[0],self.agent_pos[1]]=OBJECT_TO_IDX['agent']\n",
    "        return grid_array.T\n",
    "    \n",
    "\n",
    "# env = SimpleEnv(render_mode=\"human\")\n",
    "# manual_control = ManualControl(env, seed=42)\n",
    "\n",
    "env = SimpleEnv()\n",
    "env.reset()\n",
    "print(env.get_array_repr())\n",
    "\n",
    "# enable manual control for testing\n",
    "# manual_control.start()\n",
    "\n",
    "map_numbers = [1,2,8,10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c468843",
   "metadata": {},
   "source": [
    "#### Agent motion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83bc3d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([ 2,  2,  2,  2,  2,  2,  1,  1,  1,  2,  2,  1,  1, 10,  2,  2,  1,\n",
      "        1,  8,  2,  2,  2,  2,  2,  2,  1,  3]), array([ 2,  2,  2,  2,  2,  2,  1,  1,  1,  2,  2,  1,  1, 10,  2,  2,  1,\n",
      "        1,  8,  2,  2,  2,  2,  2,  2,  0,  0]), array([ 2,  2,  2,  2,  2,  2,  1,  1,  1,  2,  2,  1,  1, 10,  2,  2,  1,\n",
      "        1,  8,  2,  2,  2,  2,  2,  2,  2,  3])]\n"
     ]
    }
   ],
   "source": [
    "from agents.random import RandomAgent\n",
    "n_steps = 10000\n",
    "\n",
    "random_action_agent = RandomAgent(valid_actions=env.valid_actions)\n",
    "\n",
    "dirarr = ['Right', 'Down', 'Left','Up']\n",
    "actions_to_idx = {Actions.left:0, Actions.right:1, Actions.forward:2}\n",
    "\n",
    "image_list = []\n",
    "\n",
    "for i in range(n_steps):\n",
    "    action = random_action_agent.act()\n",
    "    arr = env.get_array_repr().flatten()\n",
    "    arr = np.append(arr, [actions_to_idx[action], env.agent_dir])\n",
    "    image_list.append(arr)\n",
    "    # print(dirarr[env.agent_dir])\n",
    "    # print(action)\n",
    "    env.step(action)\n",
    "    # print(env.get_array_repr())\n",
    "\n",
    "print(image_list[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256f2565",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "64fb66f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db192e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1+cu121\n",
      "True\n",
      "0\n",
      "NVIDIA GeForce MX330\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())  # This should return True if CUDA is available\n",
    "print(torch.cuda.current_device())  # Shows the current GPU device id (e.g., 0)\n",
    "print(torch.cuda.get_device_name(0))  # Displays the GPU name\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bdd3d1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#(Modified) Neuromatch helper funcitons\n",
    "def init_weights_kaiming_normal(layer):\n",
    "  \"\"\"\n",
    "  Initializes weights from linear PyTorch layer\n",
    "  with kaiming normal distribution.\n",
    "\n",
    "  Args:\n",
    "    layer (torch.Module)\n",
    "        Pytorch layer\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  # check for linear PyTorch layer\n",
    "  if isinstance(layer, nn.Linear):\n",
    "    # initialize weights with kaiming normal distribution\n",
    "    nn.init.kaiming_normal_(layer.weight.data)\n",
    "    \n",
    "\n",
    "def runSGD(net, input_train, target_train, input_test, target_test, criterion='mse',\n",
    "           n_epochs=10, batch_size=32, verbose=False):\n",
    "  \"\"\"\n",
    "  Trains autoencoder network with stochastic gradient descent with Adam\n",
    "  optimizer and loss criterion. Train samples are shuffled, and loss is\n",
    "  displayed at the end of each opoch for both MSE and BCE. Plots training loss\n",
    "  at each minibatch (maximum of 500 randomly selected values).\n",
    "\n",
    "  Args:\n",
    "    net (torch network)\n",
    "        ANN object (nn.Module)\n",
    "\n",
    "    input_train (torch.Tensor)\n",
    "        vectorized input images from train set\n",
    "\n",
    "    input_test (torch.Tensor)\n",
    "        vectorized input images from test set\n",
    "\n",
    "    criterion (string)\n",
    "        train loss: 'bce' or 'mse'\n",
    "\n",
    "    n_epochs (boolean)\n",
    "        number of full iterations of training data\n",
    "\n",
    "    batch_size (integer)\n",
    "        number of element in mini-batches\n",
    "\n",
    "    verbose (boolean)\n",
    "        print final loss\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "\n",
    "  # 1. Define the device\n",
    "  # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "  device = torch.device('cpu')\n",
    "  print(f\"Using device: {device}\")\n",
    "\n",
    "  # 2. Move the network to the device\n",
    "  net.to(device)\n",
    "\n",
    "  # 3. Move the main tensors to the device (crucial for initial setup)\n",
    "  input_train = input_train.to(device)\n",
    "  target_train = target_train.to(device)\n",
    "  input_test = input_test.to(device)\n",
    "  target_test = target_test.to(device)\n",
    "\n",
    "  # Initialize loss function\n",
    "  if criterion == 'mse':\n",
    "    loss_fn = nn.MSELoss()\n",
    "  elif criterion == 'bce':\n",
    "    loss_fn = nn.BCELoss()\n",
    "  elif criterion == 'cel':\n",
    "    loss_fn = nn.CrossEntropyLoss() \n",
    "  else:\n",
    "    print('Please specify either \"mse\" or \"bce\" for loss criterion')\n",
    "\n",
    "  # Move the loss function to the device if it has parameters (CrossEntropyLoss does not, \n",
    "  # but it's good practice for others like L1Loss which might have reduction='none')\n",
    "  loss_fn.to(device)\n",
    "\n",
    "  # Initialize SGD optimizer\n",
    "  optimizer = optim.Adam(net.parameters())\n",
    "\n",
    "  # Placeholder for loss\n",
    "  track_loss = []\n",
    "\n",
    "  print('Epoch', '\\t', 'Loss train', '\\t', 'Loss test')\n",
    "  for i in range(n_epochs):\n",
    "\n",
    "    \n",
    "    shuffle_idx = np.random.permutation(len(input_train))\n",
    "\n",
    "    batches_input = torch.split(input_train[shuffle_idx], batch_size)\n",
    "    batches_target = torch.split(target_train[shuffle_idx], batch_size)\n",
    "\n",
    "    batches = zip(batches_input, batches_target)\n",
    "\n",
    "\n",
    "    shuffle_idx = np.random.permutation(len(input_train))\n",
    "    # batches = torch.split(input_train[shuffle_idx], batch_size)\n",
    "    # for batch in batches:\n",
    "    #   output_train = net(batch)\n",
    "    #   loss = loss_fn(output_train, batch)\n",
    "    for batch_input, batch_target in batches:\n",
    "      batch_input = batch_input.float()\n",
    "      batch_target = batch_target.float()\n",
    "      output_train = net(batch_input)  # Forward pass on the input batch\n",
    "      loss = loss_fn(output_train, batch_target)  # Compare output with the target\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # Keep track of loss at each epoch\n",
    "      track_loss += [float(loss)]\n",
    "\n",
    "    loss_epoch = f'{i+1}/{n_epochs}'\n",
    "    with torch.no_grad():\n",
    "      output_train = net(input_train)\n",
    "      loss_train = loss_fn(output_train, target_train)\n",
    "      loss_epoch += f'\\t {loss_train:.4f}'\n",
    "\n",
    "      output_test = net(input_test)\n",
    "      loss_test = loss_fn(output_test, target_test)\n",
    "      loss_epoch += f'\\t\\t {loss_test:.4f}'\n",
    "\n",
    "    print(loss_epoch)\n",
    "\n",
    "  if verbose:\n",
    "    # Print loss\n",
    "    loss_mse = f'\\nMSE\\t {eval_mse(output_train, target_train):0.4f}'\n",
    "    loss_mse += f'\\t\\t {eval_mse(output_test, target_test):0.4f}'\n",
    "    print(loss_mse)\n",
    "\n",
    "    loss_bce = f'BCE\\t {eval_bce(output_train, target_train):0.4f}'\n",
    "    loss_bce += f'\\t\\t {eval_bce(output_test, target_test):0.4f}'\n",
    "    print(loss_bce)\n",
    "\n",
    "  # Plot loss\n",
    "  step = int(np.ceil(len(track_loss) / 500))\n",
    "  x_range = np.arange(0, len(track_loss), step)\n",
    "  plt.figure()\n",
    "  plt.plot(x_range, track_loss[::step], 'C0')\n",
    "  plt.xlabel('Iterations')\n",
    "  plt.ylabel('Loss')\n",
    "  plt.xlim([0, None])\n",
    "  plt.ylim([0, None])\n",
    "  plt.show()\n",
    "  print(device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00c0d9a3",
   "metadata": {},
   "source": [
    "#### Input preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f1276ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2, 2, 2,  ..., 2, 0, 0],\n",
      "        [2, 2, 2,  ..., 2, 2, 3],\n",
      "        [2, 2, 2,  ..., 2, 0, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 2, 0, 2],\n",
      "        [2, 2, 2,  ..., 2, 1, 1],\n",
      "        [2, 2, 2,  ..., 2, 1, 2]])\n",
      "tensor([[2, 2, 2,  ..., 2, 1, 3],\n",
      "        [2, 2, 2,  ..., 2, 0, 0],\n",
      "        [2, 2, 2,  ..., 2, 2, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 2, 0, 3],\n",
      "        [2, 2, 2,  ..., 2, 0, 2],\n",
      "        [2, 2, 2,  ..., 2, 1, 1]])\n"
     ]
    }
   ],
   "source": [
    "# X_train, X_test = train_test_split(image_list, test_size=0.2, random_state=42)\n",
    "test_size=0.2\n",
    "cutoff = int((1-test_size)*len(image_list))\n",
    "X_train, X_test = image_list[:cutoff], image_list[cutoff:] \n",
    "\n",
    "target_train = X_train[1:]\n",
    "input_train = X_train[:-1]\n",
    "target_test = X_test[1:]\n",
    "input_test = X_test[:-1]\n",
    "\n",
    "target_train = torch.tensor(target_train, dtype=torch.int64)\n",
    "input_train = torch.tensor(input_train, dtype=torch.int64)\n",
    "target_test = torch.tensor(target_test, dtype=torch.int64)\n",
    "input_test = torch.tensor(input_test, dtype=torch.int64)\n",
    "\n",
    "\n",
    "def one_hot_encode_set(values, classes):\n",
    "    classdict = {}\n",
    "    for i in range(len(classes)):\n",
    "        classdict[classes[i]] = i\n",
    "    one_hot = torch.zeros(len(classes))\n",
    "    one_hot[classdict[values.item()]] = 1\n",
    "    return one_hot\n",
    "\n",
    "def continuous_class(values, classes, direct):\n",
    "    classdict = {}\n",
    "    for i in range(len(classes)):\n",
    "        classdict[classes[i]] = i\n",
    "    val = classdict[values.item()]\n",
    "    if (values.item()==10):\n",
    "        val+=direct\n",
    "    return torch.tensor([val])\n",
    "\n",
    "\n",
    "# Define a function for one-hot encoding\n",
    "def one_hot_encode(values, num_classes):\n",
    "    one_hot = torch.zeros(num_classes)\n",
    "    one_hot[values] = 1\n",
    "    return one_hot\n",
    "\n",
    "# Function to process the entire array (each input array of shape [length])\n",
    "def process_input(input_array, mode):\n",
    "    if mode == 'in':\n",
    "    \n",
    "        # first_part = torch.cat([one_hot_encode(input_array[i], 11) for i in range(25)])\n",
    "        # first_part = torch.cat([one_hot_encode_set(input_array[i], map_numbers) for i in range(25)])\n",
    "        first_part = torch.cat([continuous_class(input_array[i], map_numbers, input_array[26]) for i in range(25)])\n",
    "\n",
    "        # 26th position: one-hot encoded into 3 classes\n",
    "        second_part = one_hot_encode(input_array[25], 3)\n",
    "        \n",
    "        # Last position: one-hot encoded into 4 classes\n",
    "        # third_part = one_hot_encode(input_array[26], 4)\n",
    "\n",
    "        # print(torch.cat([first_part, second_part, third_part], dim=0))\n",
    "        # Concatenate all parts to form the final one-hot encoded array\n",
    "        return torch.cat([first_part, second_part], dim=0)\n",
    "    elif mode == 'out':\n",
    "        return torch.cat([continuous_class(input_array[i], map_numbers, input_array[26]) for i in range(25)])\n",
    "\n",
    "\n",
    "# Apply to the whole dataset\n",
    "input_orientation_train = [x[26] for x in input_train]\n",
    "input_orientation_test = [x[26] for x in input_test]\n",
    "target_orientation_train = [x[26] for x in target_train]\n",
    "target_orientation_test = [x[26] for x in target_test]\n",
    "\n",
    "# Apply to the whole dataset\n",
    "input_train_processed = torch.stack([process_input(x, 'in') for x in input_train])\n",
    "input_test_processed = torch.stack([process_input(x, 'in') for x in input_test])\n",
    "target_train_processed = torch.stack([process_input(x, 'out') for x in target_train])\n",
    "target_test_processed = torch.stack([process_input(x, 'out') for x in target_test])\n",
    "\n",
    "\n",
    "print(target_train)\n",
    "print(input_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b84df5",
   "metadata": {},
   "source": [
    "#### Autoencoder definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "43198093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoder \n",
      "\n",
      " Sequential(\n",
      "  (0): Linear(in_features=28, out_features=420, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=420, out_features=20, bias=True)\n",
      "  (3): ReLU()\n",
      ")\n",
      "\n",
      "Decoder \n",
      "\n",
      " Sequential(\n",
      "  (4): Linear(in_features=20, out_features=375, bias=True)\n",
      "  (5): ReLU()\n",
      "  (6): Linear(in_features=375, out_features=25, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "encoding_size=20\n",
    "input_size=input_train_processed.size(1)\n",
    "output_size = target_train_processed.size(1)\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(input_size, int(input_size * 15)),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(int(input_size * 15), encoding_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(encoding_size, int(output_size * 15)),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(int(output_size *15), output_size),\n",
    "    )\n",
    "\n",
    "# model[:-2].apply(init_weights_kaiming_normal)\n",
    "\n",
    "n_l = 4\n",
    "encoder = model[:n_l]\n",
    "decoder = model[n_l:]\n",
    "print(f'Encoder \\n\\n {encoder}\\n')\n",
    "print(f'Decoder \\n\\n {decoder}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c672a46",
   "metadata": {},
   "source": [
    "#### Autoencoder training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "19c23a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Epoch \t Loss train \t Loss test\n",
      "1/10\t 0.1896\t\t 0.1923\n",
      "2/10\t 0.1413\t\t 0.1444\n",
      "3/10\t 0.0972\t\t 0.0985\n",
      "4/10\t 0.0642\t\t 0.0685\n",
      "5/10\t 0.0368\t\t 0.0405\n",
      "6/10\t 0.0256\t\t 0.0278\n",
      "7/10\t 0.0137\t\t 0.0156\n",
      "8/10\t 0.0083\t\t 0.0099\n",
      "9/10\t 0.0043\t\t 0.0054\n",
      "10/10\t 0.0130\t\t 0.0153\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "batch_size = 16\n",
    "\n",
    "runSGD(model, input_train_processed, target_train_processed, input_test_processed, target_test_processed, n_epochs=n_epochs, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "8c6af472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cell 18\n",
      "cell 35\n",
      "cell 40\n",
      "cell 43\n",
      "cell 97\n",
      "cell 152\n",
      "cell 206\n",
      "cell 206\n",
      "cell 229\n",
      "cell 241\n",
      "cell 241\n",
      "cell 245\n",
      "cell 268\n",
      "cell 276\n",
      "cell 281\n",
      "cell 282\n",
      "cell 305\n",
      "cell 317\n",
      "cell 325\n",
      "cell 329\n",
      "cell 332\n",
      "cell 333\n",
      "cell 359\n",
      "cell 378\n",
      "cell 399\n",
      "cell 414\n",
      "cell 432\n",
      "cell 453\n",
      "cell 460\n",
      "cell 466\n",
      "cell 466\n",
      "cell 524\n",
      "cell 555\n",
      "cell 569\n",
      "cell 593\n",
      "cell 608\n",
      "cell 614\n",
      "cell 618\n",
      "cell 623\n",
      "cell 636\n",
      "cell 654\n",
      "cell 654\n",
      "cell 672\n",
      "cell 681\n",
      "cell 682\n",
      "cell 700\n",
      "cell 700\n",
      "cell 762\n",
      "cell 799\n",
      "cell 810\n",
      "cell 867\n",
      "cell 891\n",
      "cell 897\n",
      "cell 975\n",
      "cell 975\n",
      "cell 997\n",
      "cell 997\n",
      "cell 1001\n",
      "cell 1011\n",
      "cell 1026\n",
      "cell 1032\n",
      "cell 1033\n",
      "cell 1135\n",
      "cell 1145\n",
      "cell 1195\n",
      "cell 1204\n",
      "cell 1210\n",
      "cell 1248\n",
      "cell 1300\n",
      "cell 1300\n",
      "cell 1341\n",
      "cell 1341\n",
      "cell 1362\n",
      "cell 1418\n",
      "cell 1433\n",
      "cell 1452\n",
      "cell 1492\n",
      "cell 1497\n",
      "cell 1498\n",
      "cell 1570\n",
      "cell 1570\n",
      "cell 1572\n",
      "cell 1591\n",
      "cell 1591\n",
      "cell 1606\n",
      "cell 1631\n",
      "cell 1644\n",
      "cell 1645\n",
      "cell 1669\n",
      "cell 1687\n",
      "cell 1739\n",
      "cell 1774\n",
      "cell 1776\n",
      "cell 1804\n",
      "cell 1804\n",
      "cell 1815\n",
      "cell 1829\n",
      "cell 1831\n",
      "cell 1835\n",
      "cell 1836\n",
      "cell 1842\n",
      "cell 1857\n",
      "cell 1869\n",
      "cell 1888\n",
      "cell 1904\n",
      "cell 1904\n",
      "cell 1909\n",
      "cell 1923\n",
      "cell 1934\n",
      "cell 1947\n",
      "cell 1950\n",
      "tensor([[2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 3],\n",
      "        [2, 2, 2,  ..., 2, 2, 3],\n",
      "        ...,\n",
      "        [2, 2, 2,  ..., 2, 2, 2],\n",
      "        [2, 2, 2,  ..., 2, 2, 3],\n",
      "        [2, 2, 2,  ..., 2, 2, 3]])\n",
      "Cell accuracy: 0.9977788894447224\n",
      "Agent orientation accuracy: 0.8549274637318659\n",
      "Number of agents accuracy: 0.9934967483741871\n"
     ]
    }
   ],
   "source": [
    "input_test_processed = input_test_processed.to(device)\n",
    "output = model(input_test_processed)  # Model output (logits or probabilities)\n",
    "# torch.set_printoptions(profile=\"full\")\n",
    "# print(output)\n",
    "output = output.cpu() \n",
    "# Initialize a list to hold the decoded outputs for each observation\n",
    "decoded_outputs = []\n",
    "\n",
    "incorrect_agent_num=0\n",
    "incorrect_orientation=0\n",
    "incorrect_cell=0\n",
    "\n",
    "for i in range(output.size(0)):  # Loop over each sample in the batch\n",
    "    # Extract the blocks of the output\n",
    "    first_25 = output[i]\n",
    "    # second_block = output[i, input_train_processed.size(1)-7:input_train_processed.size(1)-4]    # Next block of size 3\n",
    "    # third_block = output[i, input_train_processed.size(1)-7:]             # Last block of size 4\n",
    "\n",
    "    # Decode each block by taking the argmax (index of max value)\n",
    "    decoded_first_25 = torch.round(first_25).long()  # 25 values, each between 0-10\n",
    "    # decoded_second = torch.argmax(second_block)       # Single value between 0-2\n",
    "    # decoded_third = torch.argmax(third_block)         # Single value between 0-3\n",
    "    \n",
    "    map_array = map_numbers+[11,12,13]\n",
    "    in_map_array = torch.isin(decoded_first_25, torch.tensor(range(len(map_array))))\n",
    "    # Convert values not in map_array to len(map_array)\n",
    "    adjusted_values = torch.where(in_map_array, decoded_first_25, torch.tensor(len(map_array)))\n",
    "    mapping = torch.tensor(map_array+[-1])\n",
    "    decoded_first_25 = mapping[adjusted_values]\n",
    "\n",
    "    num_agents = 0\n",
    "\n",
    "    for j, val in enumerate(decoded_first_25):\n",
    "        if val >= 10 and num_agents == 0:\n",
    "            decoded_second = val -10\n",
    "        if val>= 10:\n",
    "            num_agents +=1\n",
    "        if (target_test[i, j] != val and (val < 10 or target_test[i, j] < 10)):\n",
    "            print(\"cell\", i)\n",
    "            incorrect_cell +=1\n",
    "    \n",
    "    decoded_first_25[decoded_first_25 > 10] = 10\n",
    "\n",
    "    if num_agents != 1:\n",
    "        decoded_second = torch.tensor(-1, dtype=torch.long)\n",
    "        incorrect_agent_num +=1\n",
    "    \n",
    "    if (decoded_second != target_orientation_test[i]):\n",
    "        incorrect_orientation +=1\n",
    "\n",
    "    # Use torch.masked_select to get all matching values\n",
    "    matches = torch.masked_select(decoded_first_25, decoded_first_25 >= 10)\n",
    "\n",
    "    # Ensure it's a 1D tensor for concatenation\n",
    "    decoded_second = decoded_second.unsqueeze(0)\n",
    "\n",
    "    # Combine the decoded values into a single list for this observation\n",
    "    decoded_sample = torch.cat([decoded_first_25, decoded_second])\n",
    "    \n",
    "    # Append the decoded sample to the final list\n",
    "    decoded_outputs.append(decoded_sample)\n",
    "\n",
    "acc_cell = 1.0-(incorrect_cell/(25*output.size(0)))\n",
    "acc_orientation = 1.0-(incorrect_orientation/output.size(0))\n",
    "acc_agentnum = 1.0-(incorrect_agent_num/output.size(0))\n",
    "\n",
    "# Convert to tensor if needed\n",
    "decoded_outputs = torch.stack(decoded_outputs)\n",
    "print(decoded_outputs)\n",
    "\n",
    "print (\"Cell accuracy:\", acc_cell)\n",
    "print (\"Agent orientation accuracy:\", acc_orientation)\n",
    "print (\"Number of agents accuracy:\", acc_agentnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e7485691",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample 1:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 2:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 3:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 4:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 5:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1, 10,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 6:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "Decoded Orientation: 1 | Target Orientation: 1 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 7:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 3 | Target Orientation: 2 | Input Orientation: 1\n",
      "==================================================\n",
      "Sample 8:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1, 10,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 9:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 10:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 11:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 12:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 13:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 14:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 0 | Target Orientation: 0 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 15:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 1 | Target Orientation: 1 | Input Orientation: 0\n",
      "==================================================\n",
      "Sample 16:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 1 | Target Orientation: 1 | Input Orientation: 1\n",
      "==================================================\n",
      "Sample 17:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 1\n",
      "==================================================\n",
      "Sample 18:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 2 | Target Orientation: 3 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 19:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  8,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 0 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 20:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 21:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 22:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 23:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 24:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 0 | Target Orientation: 0 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 25:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 0\n",
      "==================================================\n",
      "Sample 26:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 0\n",
      "Decoded Orientation: 2 | Target Orientation: 2 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 27:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 3 | Target Orientation: 3 | Input Orientation: 2\n",
      "==================================================\n",
      "Sample 28:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 0 | Target Orientation: 0 | Input Orientation: 3\n",
      "==================================================\n",
      "Sample 29:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 1\n",
      "Decoded Orientation: 1 | Target Orientation: 1 | Input Orientation: 0\n",
      "==================================================\n",
      "Sample 30:\n",
      "Input Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Decoded Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Target Grid:\n",
      "tensor([[ 2,  2,  2,  2,  2],\n",
      "        [ 2,  1,  1,  1,  2],\n",
      "        [ 2, 10,  1,  1,  2],\n",
      "        [ 2,  1,  1,  8,  2],\n",
      "        [ 2,  2,  2,  2,  2]], dtype=torch.int32)\n",
      "Input Action: 2\n",
      "Decoded Orientation: 1 | Target Orientation: 1 | Input Orientation: 1\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "for i in range(min(30,decoded_outputs.size(0))):\n",
    "    # Print the input, decoded grid, and target test grid side by side\n",
    "    print(f\"Sample {i + 1}:\")\n",
    "    \n",
    "    # Input grid (first 25 values reshaped into 5x5)\n",
    "    print(\"Input Grid:\")\n",
    "    print(input_test[i, :25].reshape(5, 5).int())\n",
    "    \n",
    "    # Decoded grid (first 25 values reshaped into 5x5)\n",
    "    print(\"Decoded Grid:\")\n",
    "    print(decoded_outputs[i, :25].reshape(5, 5).int())\n",
    "    \n",
    "    # Target test grid (first 25 values reshaped into 5x5)\n",
    "    print(\"Target Grid:\")\n",
    "    print(target_test[i, :25].reshape(5, 5).int())\n",
    "    \n",
    "    # Action and Orientation for input, decoded, and target test\n",
    "    print(f\"Input Action: {input_test[i, 25].item()}\")\n",
    "    print(f\"Decoded Orientation: {decoded_outputs[i, 25].item()} | Target Orientation: {target_orientation_test[i].item()} | Input Orientation: {input_orientation_test[i].item()}\")\n",
    "    \n",
    "    print(\"=\" * 50)  # Separator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085f2204",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mg10 (3.10.18)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
